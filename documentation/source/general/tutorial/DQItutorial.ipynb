{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064416cf",
   "metadata": {},
   "source": [
    "# Decoding by Quantum Interferometry\n",
    "\n",
    "In this tutorial, we will show you the Qrisp implementation of the [Optimization by Decoded Quantum Interferometry](https://arxiv.org/abs/2408.08292) and its relevant subroutines.  \n",
    "This algorithm is rigorously derived in the original paper, including motivation with physical intuition, so we highly recommend giving it a read!  \n",
    "\n",
    "Additionally, the 2025 paper [Quantum Circuit Design for Decoded Quantum Interferometry](https://arxiv.org/abs/2504.18334) goes into circuit design for this algorithm (as the title suggests) and is worth investigating as well!  \n",
    "We will cross-reference these two papers throughout the text where applicable, so you know where to look for specific details.\n",
    "Let us quickly summarize what the original paper is about:\n",
    "\n",
    "The **Decoded Quantum Interferometry (DQI)** algorithm uses the **quantum Fourier transform** to arrange amplitudes so that they interfere constructively on symbol strings with high objective values. This increases the probability of measuring good solutions. The procedure effectively reduces optimization problems to decoding problems.\n",
    "Specifically, sparse unstructured optimization problems such as **max-k-XORSAT** are reduced to decoding of **low-density parity-check (LDPC)** codes.\n",
    "Let us dive into how this works with the example of the **max-XORSAT** problem, which is defined as follows:\n",
    "\n",
    "You are given a system of $ m $ XOR (exclusive OR) equations over $ n $ binary variables: $x_{i_1} \\oplus x_{i_2} \\oplus \\dots \\oplus x_{i_k} = b_j$,\n",
    "where:\n",
    "- $ x_i \\in \\{0, 1\\} $ are Boolean variables,  \n",
    "- $ \\oplus $ denotes addition modulo 2 (XOR),  \n",
    "- $ b_j \\in \\{0, 1\\} $ are fixed constants,  \n",
    "- each equation (or clause) involves a subset of variables.  \n",
    "\n",
    "The goal in **max-XORSAT** is to find an assignment to the variables $ x_i $ that maximizes the number of satisfied XOR equations.\n",
    "\n",
    "The max-XORSAT problem can be rephrased as maximizing the objective function $ f(\\mathbf{x}) = \\sum_{i=1}^{m} (-1)^{v_i + \\mathbf{b}_i \\times \\mathbf{x}}$ where $ \\mathbf{b}_i $ is the $ i $-th row of $ B $, a matrix in which each row represents one of the XOR equations. So $ f(\\mathbf{x}) $ is the number of linear equations that are satisfied minus the number of unsatisfied ones.\n",
    "\n",
    "Now, the **Hadamard transform** of this function will be sparse. Only for the strings $ \\mathbf{b}_1, \\ldots, \\mathbf{b}_m $ the amplitudes will be nonzero, so we only have $ m $ nonzero amplitudes in total. So if we can prepare the superposition $ \\sum_{i=1}^{m} (-1)^{v_i} \\ket{\\mathbf{b}_i}$\n",
    "and apply the Hadamard transform, then we will arrive at $ \\sum_{\\mathbf{x} \\in \\{0,1\\}^{\\otimes n}} f(\\mathbf{x}) \\ket{\\mathbf{x}}$\n",
    "\n",
    "This state is then biased towards higher objective-value strings $ \\mathbf{x} $.  \n",
    "With a higher amplitude and objective value $ f(\\mathbf{x}) $, they are more likely to be measured.\n",
    "A slight bias is obviously not enough — but how can we improve this?  \n",
    "The answer is by introducing a polynomial $ P $ to encode our function $ f $, turning it into a **decoding problem**.\n",
    "\n",
    "This **polynomial encoding** with $ P $ amplifies amplitude differences between basis states based on their objective values, by reweighting the amplitudes and introducing higher-order correlations in the Hadamard basis.  \n",
    "When an initial superposition $ f(\\mathbf{x}) \\ket{\\mathbf{x}} $ would encode the objective value linearly (i.e., measuring $ \\ket{\\mathbf{x}} $ is proportional to its amplitude $ f(\\mathbf{x}) $), a degree-2 polynomial can encode the objective value **quadratically**. When the resulting state $ \\ket{P(f)} $ is measured in the computational basis, a string $ \\mathbf{x} $ is obtained with probability proportional to $ P(f(x))^2 $.  \n",
    "We therefore want to prepare the state\n",
    "\n",
    "$$\n",
    "\\ket{P(f)} = \\sum_{\\mathbf{x} \\in \\{0,1\\}^{\\otimes n}} P(f(\\mathbf{x})) \\ket{\\mathbf{x}}\n",
    "$$\n",
    "\n",
    "Interpreting $ P(f) $ as a decoding function gives us a recipe for the necessary **uncomputation**:  \n",
    "The state encodes phase information similar to a **syndrome**, i.e., an erroneous state within the context of quantum error correction (more on this in the uncomputation section).  \n",
    "\n",
    "The process of preparing this state requires inferring the error vector $ \\ket{y} $ from the syndrome $ B^T \\mathbf{y} $ and uncomputing $ \\ket{y} $ in superposition — which is precisely the task of **syndrome decoding** for a linear error-correcting code.  \n",
    "So in this step, we will employ well-known techniques from this field.\n",
    "\n",
    "As a further note, the higher the degree $ l $ of the polynomial $ P $, the greater the bias toward measured bit strings with large objective values. This powerful encoding, however, introduces a **fundamental trade-off**: the polynomial degree $ l $ must be chosen such that it corresponds to the maximum number of errors the underlying decoding system can correct — meaning a larger $ l $ requires solving a harder decoding problem.\n",
    "\n",
    "For the max-XORSAT case, the derivation of $ \\ket{P(f)} $ can be found on [p. 19 in the first paper](https://arxiv.org/abs/2504.18334#page=19).\n",
    "\n",
    "## Steps in the algorithm\n",
    "\n",
    "### Preparing the State $\\ket{P(f)}$\n",
    "\n",
    "To arrive at the state $\\ket{P(f)}$, five steps are conducted.  \n",
    "The first one is to prepare a **Dicke state superposition** $\\sum_{k=0}^{l} w_k \\ket{D_{m,k}}$, where\n",
    "$$\n",
    "\\ket{D_{m,k}} = \\frac{1}{\\sqrt{\\binom{m}{k}}} \\sum_{|y| = k} \\ket{\\mathbf{y}}$$\n",
    "i.e. the Dicke state of weight $k$.  \n",
    "We will make use of our established [Dicke state tutorial (REF, the Dicke state tut)]() for this.  \n",
    "The coefficients $w_k$ emerge as the **principal eigenvector** of a matrix built in relation to the expected number of satisfied constraints. Please refer to *Lemma 9.2* in the [DQI paper](https://arxiv.org/pdf/2408.08292) to see how we can define this matrix. The weights will then be fanned out via **unary amplitude encoding**. \n",
    "We will touch on this again in the implementation section.\n",
    "\n",
    "The next step is to consider the **problem-specific phase** $(-1)^{\\mathbf{v} \\cdot \\mathbf{y}}$ via conditional $Z$-gates. Recall that $\\mathbf{v}$ emerges from the initial equation $B \\mathbf{x} = \\mathbf{v}$ that we are trying to solve. Then, the problem matrix will be encoded into the second register, such that we receive the state $\\ket{B^T \\mathbf{y}}$ as part of our superposition.  \n",
    "After this step, we will have the state\n",
    "\n",
    "$$\n",
    "\\sum_{k=0}^{l} w_k \\frac{1}{\\sqrt{\\binom{m}{k}}} \n",
    "\\sum_{|y| = k} (-1)^{\\mathbf{v} \\cdot \\mathbf{y}} \n",
    "\\ket{\\mathbf{y}} \\ket{B^T \\mathbf{y}}\n",
    "$$\n",
    "\n",
    "Now, at this point, we want to refer again to the **biased polynomial** $\\ket{P(f)}$, which encodes problem solutions with high likelihood. Its **Hadamard transform** will always be of the form:\n",
    "\n",
    "$$\n",
    "H^{\\otimes n} \\ket{P(f)} = \n",
    "\\sum_{k=0}^{l} w_k \\frac{1}{\\sqrt{\\binom{m}{k}}} \n",
    "\\sum_{|y| = k} (-1)^{\\mathbf{v} \\cdot \\mathbf{y}} \\ket{B^T \\mathbf{y}}\n",
    "$$\n",
    "\n",
    "So after the previous step of encoding the problem matrix $B$, we are just one **uncomputation of $\\ket{\\mathbf{y}}$** (and a straightforward Hadamard transform) away from our desired polynomial state $\\ket{P(f)}$.\n",
    "\n",
    "### Uncomputation and Decoding\n",
    "\n",
    "Unfortunately, said uncomputation is the hard part of the algorithm. With the structure of $B$, this turns the task into a **decoding problem**, a problem studied in the context of, e.g., low-density parity-check matrices for error correction.\n",
    "\n",
    "In error correction we deal with so-called stabiliser codes to facilitate error correction. When one measures the stabilisers of a quantum error-correcting code, a binary outcome vector is obtained that indicates which parity checks have been violated and thus signals the presence and location of errors. These so-called *syndromes* are the result of multiplying the error vector by the transpose of the parity-check (or stabiliser) matrix. In the DQI algorithm, one interprets the matrix $B^T \\mathbf{y}$ as the parity-check operator and the state $\\ket{B^T \\mathbf{y}}$ holds the syndrome, which is then decoded to infer $y$ (the “error pattern”) and thus enables the uncomputation step that biases the quantum amplitudes toward good solutions.\n",
    "\n",
    "Without going into much detail, we want to mention three approaches to tackle this problem for our purposes here, which are also considered in the [original DQI paper](https://arxiv.org/abs/2408.08292), namely: [Belief Propagation](https://arxiv.org/pdf/2102.01984), Look-Up tables (see [Decoding methods](https://en.wikipedia.org/wiki/Decoding_methods)), and the quantum version of a Gauss–Jordan elimination (see [quant-ph/0511062](https://arxiv.org/pdf/quant-ph/0511062)).\n",
    "\n",
    "Our solution relies on the quantum version of a Gauss–Jordan elimination, which lies somewhere in the middle of belief propagation and look-up tables in terms of efficiency and resource demand.  \n",
    "You might ask yourself: What is Gauss–Jordan elimination? And how do we make it quantum? That is a great question, so let’s answer it!\n",
    "\n",
    "A [Gauss–Jordan elimination](https://en.wikipedia.org/wiki/Gaussian_elimination) is used to bring a matrix into reduced row echelon form, i.e., applying row operations until you have reached the reduced upper-triangular form. In the case of an invertible matrix, one computes its inverse in this way. For our purpose, this inversion property effectively results in the isolation of a syndrome in the corresponding augmented matrix, i.e., the problem matrix extended by the syndrome vector. We will see what this looks like in the implementation part. You can find more information on the Quantum Gauss–Jordan Elimination and its use in syndrome decoding in the [thesis on Independent Set Decoding (S. Perillo et al.)](https://www.politesi.polimi.it/retrieve/ef311c33-5427-4869-865f-94dc5ee733ed/Thesis.pdf#page=92).\n",
    "\n",
    "Our DQI implementation does not employ a fully quantum Gauss–Jordan elimination but translates the classical row-operation steps into quantum gates acting on the syndrome register.\n",
    "Since $B$ is classical, we can precompute the required transformations and map them to quantum gates — classical swaps become [swap()](../../reference/Primitives/generated/qrisp.swap.rst) gates, and additions become [cx()](../../reference/Primitives/generated/qrisp.cx.rst) gates. This approach minimizes resource overhead and avoids failure in the case of a non-invertible matrix.\n",
    "\n",
    "It is important to note here that our chosen routine may still produce erroneous uncomputations, and we need to post-select on the correct ones. The latter are characterized by the respective register being measured as all $\\ket{0}$.\n",
    "\n",
    "\n",
    "# DQI Implementation in Qrisp\n",
    "\n",
    "\n",
    "Now that we have covered the theoretical aspect of the algorithm, let us jump into our implementation! We want to remind you again, that the theoretical aspects of the DQI procedure are very complex, and we can only cover so much here. So, if there are any questions left unanswered, we strongly recommend taking the time to read the [original paper by S. Jordan et. al.](https://arxiv.org/abs/2408.08292) \n",
    "Let’s reiterate — the algorithm consists of five main steps executed on two registers: the **error register** and the **syndrome register**, as shown below\n",
    "\n",
    "<img src=\"../../_static/dqi_state_manipulation.png\" class=\"align-center\" width=\"1200\" alt=\"DQI algorithm steps\" />\n",
    "\n",
    "The complete process to prepare the desired polynomial-encoded state $\\ket{P(f)}$ consists of the following steps:\n",
    "\n",
    "1. **Prepare the correctly weighted Dicke state**\n",
    "\n",
    "   $$\n",
    "   \\sum_{k=0}^{l} w_k \\ket{D_{m,k}}\n",
    "   $$\n",
    "\n",
    "2. **Encode the problem-specific phases**\n",
    "\n",
    "   $$\n",
    "   \\sum_{k=0}^{l} w_k \\frac{1}{\\sqrt{\\binom{m}{k}}}\n",
    "   \\sum_{|y| = k} (-1)^{\\mathbf{v} \\cdot \\mathbf{y}}\n",
    "   \\ket{\\mathbf{y}} \\ket{B^T \\mathbf{y}}\n",
    "   $$\n",
    "\n",
    "3. **Encode the constraints given by the problem matrix**\n",
    "\n",
    "   $$\n",
    "   \\sum_{k=0}^{l} w_k \\frac{1}{\\sqrt{\\binom{m}{k}}}\n",
    "   \\sum_{|y| = k} (-1)^{\\mathbf{v} \\cdot \\mathbf{y}} \\ket{\\mathbf{y}}\n",
    "   $$\n",
    "\n",
    "4. **Uncompute the syndrome quantum state**\n",
    "\n",
    "   $$\n",
    "   \\sum_{k=0}^{l} w_k \\frac{1}{\\sqrt{\\binom{m}{k}}}\n",
    "   \\sum_{|y| = k} (-1)^{\\mathbf{v} \\cdot \\mathbf{y}}\n",
    "   \\ket{B^T \\mathbf{y}}\n",
    "   $$\n",
    "\n",
    "5. **Apply a Hadamard transform**\n",
    "\n",
    "   $$\n",
    "   \\sum_{x} P(f(x)) \\ket{x}\n",
    "   $$\n",
    "\n",
    "6. **Post-select on correctly uncomputed states**\n",
    "\n",
    "\n",
    "Before we tackle these steps, let us explain how we define the quantum registers:\n",
    "We operate on two different quantum registers, which in the context of Qrisp may be represented by any sort of multi-qubit QuantumVariable (or other type). Multiple registers, i.e. variables, may then be grouped within a [QuantumArray](../../reference/Core/QuantumArray.rst).\n",
    "The first register, which is in the literature referred to as the error register, will be represented by a QuantumVariable ``qv_error`` of size $n$. On the second register we will apply the matrix operations resulting from the Quantum Gauss-Jordan-Elimination, see the **uncomputation steps described above**. \n",
    "As mentioned previously, this routine operates on an augmented matrix, namely the transposed problem matrix augmented by the syndrome quantum state. And as you probably guessed, there is some functionality for that in Qrisp!\n",
    "It requires using a ``QuantumArray`` though, so the syndrome register, which we name ``qv_syndrome`` will be represented by a ``QuantumArray`` of length $m$ consisting of single-qubit [QuantumVariables](../../reference/Core/QuantumVariable.rst).\n",
    "\n",
    "We start our implementation by looking at the unary amplitude encoding of the error register. As mentioned in the theoretical overview, the amplitudes to encode emerge as the principal eigenvector of a matrix related to \n",
    "the expected number of satisfied constraints, which is defined in Lemma 9.2 of the [DQI paper](https://arxiv.org/pdf/2408.08292):\n",
    "It is depended on a number of parameters: We have $m$ as the number of constraints, i.e. the number of rows in the problem matrix. The prime $p$ defines our finite field $\\mathbb{F}_p$, which is set to $p=2$ in the case of max-XORSAT. Additionally, $r=1$ represents number of inputs yielding $+1$.\n",
    "\n",
    "We now construct this matrix and solve for its principal eigenvector.\n",
    "(Note: This function is adapted from [N. Patamawisut's github repo](https://github.com/BankNatchapol/DQI-Circuit/tree/main).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.sparse import diags\n",
    "def get_optimal_w(m, l, p, r):\n",
    "\n",
    "    # define the parameter d\n",
    "    d    = (p - 2*r) / np.sqrt(r * (p - r))\n",
    "    # create the main diagonal and the two offdiagonals as numpy arrays.\n",
    "    diag = np.arange(l + 1) * d\n",
    "    off  = np.sqrt(np.arange(1, l + 1) * (m - np.arange(1, l + 1) + 1))\n",
    "\n",
    "    A = diags([off, diag, off], offsets=(-1, 0, 1), format=\"csr\")\n",
    "\n",
    "    # solve for principal eigenvector\n",
    "    _, vecs = eigsh(A, k=1, which=\"LA\")\n",
    "    w = vecs.flatten()\n",
    "    \n",
    "    # pad the weights list that is returned, s.t. it is a power of 2\n",
    "    orig = len(w)\n",
    "    pad_len = 2**int(np.ceil(np.log2(l+1)))\n",
    "    weights = list(w)\n",
    "    weights += [0 for i in range((pad_len -orig)) ]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc287609",
   "metadata": {},
   "source": [
    "Next, we need to encode these amplitudes into the state to create $\\sum_k w_k \\ket{k}$. A simple fan-out strategy based on [ry()](../../reference/Primitives/generated/qrisp.ry.rst)-gates will do the trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5465a358",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nik40643\\Desktop\\tutorial_reviews\\Qrisp\\.docvenv\\Lib\\site-packages\\llvmlite\\binding\\ffi.py:141\u001b[39m, in \u001b[36m_lib_wrapper.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fntab\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# Lazily wraps new functions as they are requested\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'LLVMPY_AddSymbol'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ry, control\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34muae_encoding\u001b[39m(qa_error, num_constraints, weights):\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Normalize weights\u001b[39;00m\n\u001b[32m      5\u001b[39m     weights = weights/\u001b[38;5;28msum\u001b[39m(weights)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\tutorial_reviews\\Qrisp\\src\\qrisp\\__init__.py:28\u001b[39m\n\u001b[32m     25\u001b[39m jax.config.update(\u001b[33m\"\u001b[39m\u001b[33mjax_enable_x64\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcircuit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcircuit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\tutorial_reviews\\Qrisp\\src\\qrisp\\core\\__init__.py:20\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03m********************************************************************************\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m* Copyright (c) 2025 the Qrisp authors\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33;03m********************************************************************************\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msession_merging_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompilation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantum_variable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QuantumVariable\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantum_session\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QuantumSession\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\tutorial_reviews\\Qrisp\\src\\qrisp\\core\\compilation.py:40\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcircuit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     23\u001b[39m     QuantumCircuit,\n\u001b[32m     24\u001b[39m     Operation,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     ClControlledOperation\n\u001b[32m     38\u001b[39m )\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_depth_dic, retarget_instructions\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpermeability\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m optimize_allocations, parallelize_qc, lightcone_reduction\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# The purpose of this function is to dynamically (de)allocate qubits when they are\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# needed or not needed anymore. The qompiler function knows when a qubit is ready to\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# deallocate (ie. it is in |0> state) due to a gate called QubitDealloc. After some\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# more clean/dirty ancillae beeing available, in many cases it is also possible to\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# generate more efficient mcx implementations, thus also reducing the gate count.\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mqompiler\u001b[39m(\n\u001b[32m     62\u001b[39m     qs,\n\u001b[32m     63\u001b[39m     workspace=\u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     69\u001b[39m     use_dirty_anc_for_mcx_recomp=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     70\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\tutorial_reviews\\Qrisp\\src\\qrisp\\permeability\\__init__.py:22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpermeability\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtype_checker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpermeability\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpermeability_dag\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpermeability\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqc_transformations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\tutorial_reviews\\Qrisp\\src\\qrisp\\permeability\\qc_transformations\\__init__.py:19\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03m********************************************************************************\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m* Copyright (c) 2025 the Qrisp authors\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33;03m********************************************************************************\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpermeability\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqc_transformations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlight_cone_reduction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpermeability\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqc_transformations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory_management\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpermeability\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqc_transformations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqc_parallelization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\tutorial_reviews\\Qrisp\\src\\qrisp\\permeability\\qc_transformations\\light_cone_reduction.py:21\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03m********************************************************************************\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m* Copyright (c) 2025 the Qrisp authors\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33;03m********************************************************************************\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnx\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqrisp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpermeability\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqc_transformations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory_management\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m topological_sort\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# This function reorders the circuit such that the intended measurements can be executed\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# as early as possible. Additionally, any instructions that are not needed for the\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# intended measurements are removed\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m \n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# After that we investigate the circuit for instructions that can be removed\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlightcone_reduction\u001b[39m(qc, intended_measurements):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\tutorial_reviews\\Qrisp\\src\\qrisp\\permeability\\qc_transformations\\memory_management.py:21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnx\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m njit\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsutil\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize_allocations\u001b[39m(qc):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nik40643\\Desktop\\tutorial_reviews\\Qrisp\\.docvenv\\Lib\\site-packages\\numba\\__init__.py:73\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m get_versions\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m generate_version_info\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types, errors\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Re-export typeof\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nik40643\\Desktop\\tutorial_reviews\\Qrisp\\.docvenv\\Lib\\site-packages\\numba\\core\\config.py:17\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     14\u001b[39m     _HAVE_YAML = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllvmlite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbinding\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mll\u001b[39;00m\n\u001b[32m     20\u001b[39m IS_WIN32 = sys.platform.startswith(\u001b[33m'\u001b[39m\u001b[33mwin32\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     21\u001b[39m IS_OSX = sys.platform.startswith(\u001b[33m'\u001b[39m\u001b[33mdarwin\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nik40643\\Desktop\\tutorial_reviews\\Qrisp\\.docvenv\\Lib\\site-packages\\llvmlite\\binding\\__init__.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThings that rely on the LLVM library\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdylib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexecutionengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minitfini\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nik40643\\Desktop\\tutorial_reviews\\Qrisp\\.docvenv\\Lib\\site-packages\\llvmlite\\binding\\dylib.py:36\u001b[39m\n\u001b[32m     30\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(outerr))\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# FFI\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43mffi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLLVMPY_AddSymbol\u001b[49m.argtypes = [\n\u001b[32m     37\u001b[39m     c_char_p,\n\u001b[32m     38\u001b[39m     c_void_p,\n\u001b[32m     39\u001b[39m ]\n\u001b[32m     41\u001b[39m ffi.lib.LLVMPY_SearchAddressOfSymbol.argtypes = [c_char_p]\n\u001b[32m     42\u001b[39m ffi.lib.LLVMPY_SearchAddressOfSymbol.restype = c_void_p\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nik40643\\Desktop\\tutorial_reviews\\Qrisp\\.docvenv\\Lib\\site-packages\\llvmlite\\binding\\ffi.py:144\u001b[39m, in \u001b[36m_lib_wrapper.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fntab[name]\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# Lazily wraps new functions as they are requested\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     cfn = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lib\u001b[49m, name)\n\u001b[32m    145\u001b[39m     wrapped = _lib_fn_wrapper(\u001b[38;5;28mself\u001b[39m._lock, cfn)\n\u001b[32m    146\u001b[39m     \u001b[38;5;28mself\u001b[39m._fntab[name] = wrapped\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nik40643\\Desktop\\tutorial_reviews\\Qrisp\\.docvenv\\Lib\\site-packages\\llvmlite\\binding\\ffi.py:136\u001b[39m, in \u001b[36m_lib_wrapper._lib\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_lib\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    134\u001b[39m     \u001b[38;5;66;03m# Not threadsafe.\u001b[39;00m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lib_handle:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lib_handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nik40643\\Desktop\\tutorial_reviews\\Qrisp\\.docvenv\\Lib\\site-packages\\llvmlite\\binding\\ffi.py:122\u001b[39m, in \u001b[36m_lib_wrapper._load_lib\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _suppress_cleanup_errors(_importlib_resources_path(\n\u001b[32m    120\u001b[39m             \u001b[34m__name__\u001b[39m.rpartition(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m],\n\u001b[32m    121\u001b[39m             get_library_name())) \u001b[38;5;28;01mas\u001b[39;00m lib_path:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m         \u001b[38;5;28mself\u001b[39m._lib_handle = \u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlib_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m         \u001b[38;5;66;03m# Check that we can look up expected symbols.\u001b[39;00m\n\u001b[32m    124\u001b[39m         _ = \u001b[38;5;28mself\u001b[39m._lib_handle.LLVMPY_GetVersionInfo()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ctypes\\__init__.py:376\u001b[39m, in \u001b[36mCDLL.__init__\u001b[39m\u001b[34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28mself\u001b[39m._FuncPtr = _FuncPtr\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    378\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = handle\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from qrisp import ry, control\n",
    "def uae_encoding(qa_error, num_constraints, weights):\n",
    "    \n",
    "    # Normalize weights\n",
    "    weights = weights/sum(weights)\n",
    "    w2 = weights  \n",
    "    \n",
    "    # Calculate the cumulative\n",
    "    cum = np.concatenate(([0.0], np.cumsum(w2[:-1])))  \n",
    "    denom = 1.0 - cum\n",
    "\n",
    "    # Avoid division by zero, clip ratios\n",
    "    ratio = np.where(denom > 0, w2 / denom, 0.0)\n",
    "    ratio = np.clip(ratio, 0.0, 1.0)\n",
    "    betas = 2.0 * np.arccos(np.sqrt(ratio))\n",
    "\n",
    "    # Actual encoding \n",
    "    # Apply first RY if nonzero\n",
    "    if betas[0] != 0.0 and not np.isnan(betas[0]):\n",
    "        ry(betas[0], qa_error[0][0])\n",
    "    # Controlled rotations\n",
    "    for i in range(1, num_constraints):\n",
    "        if i < betas.size:\n",
    "            b = betas[i]\n",
    "            if b != 0.0 and not np.isnan(b):\n",
    "                with control( qa_error[i-1][0]):\n",
    "                    ry(b,  qa_error[i][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47ca4ce",
   "metadata": {},
   "source": [
    "Then we prepare a Dicke state superposition, i.e. further transform the state into $\\sum^{l}_{k=0} w_k \\frac{w_k }{\\sqrt{\\binom{m}{k}}} \\sum_{ | y | = k} \\ket{\\textbf{y}}$.\n",
    "Now this would require quite a bit of effort in any other framework. But with Qrisp, we already have according functionality in place! Which renders this as easy as calling the [dicke_state()](../../reference/Primitives/DickeStates.rst) function (or any of its variations)! We will revisit this in the complete implementation example and omit the detailed construction here.\n",
    "The subsequent step is conceptually simple and requires little additional explanation. The phase encoding applies a phase shift to the error register based on the constraint vector $\\mathbf{v}$, yielding $$\\sum^{l}_{k=0} w_k \\frac{w_k }{\\sqrt{\\binom{m}{k}}} \\sum_{ | y | = k} (-1)^{\\textbf{v} \\cdot \\textbf{y}} \\ket{\\textbf{y}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f29823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qrisp import z\n",
    "def specific_phase_encoding(qa_error, v):\n",
    "\n",
    "    for index in range(len(v)):\n",
    "        if v[index] == 1:\n",
    "            z(qa_error[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577908a",
   "metadata": {},
   "source": [
    "The last transformation before we tackle the complex decoding steps is to encode the problem matrix. \n",
    "By applying [cx()](../../reference/Primitives/generated/qrisp.cx.rst)-gates conditioned on the binary $B^T$ matrix entries, we will receive the state $$\\sum^{l}_{k=0} w_k \\frac{w_k }{\\sqrt{\\binom{m}{k}}} \\sum_{ | y | = k} (-1)^{\\textbf{v} \\cdot \\textbf{y}} \\ket{\\textbf{y}} \\ket{B^T \\textbf{y}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e39e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qrisp import cx\n",
    "def constraint_encoding(qa_error, qv_syndrome, B):\n",
    "\n",
    "    # reverse indices due to circuit definition\n",
    "    qa_error, qv_syndrome = qa_error[::-1], qv_syndrome[::-1]\n",
    "\n",
    "    # create B^T\n",
    "    B_t = np.transpose(B)\n",
    "\n",
    "    # encode constraints\n",
    "    i_ind, j_ind = B_t.shape\n",
    "    for i in range(i_ind):\n",
    "        for j in range(j_ind):\n",
    "            if  B_t[i][j] == 1: \n",
    "                cx(qa_error[j], qv_syndrome[i])\n",
    "\n",
    "    return qa_error, qv_syndrome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a84bbd",
   "metadata": {},
   "source": [
    "### Decoding implementation in Qrisp\n",
    "\n",
    "\n",
    "We now arrive at the decoding step, corresponding to the uncomputation of $\\ket{y}$. To perform this, we require a quantum version of the Gauss–Jordan elimination.\n",
    "Our implementation follows the approach proposed by N. Patamawisut et al. in their 2025 paper [Quantum Circuit Design for Decoded Quantum Interferometry](https://arxiv.org/abs/2504.18334). A code example can be found on [their github repository](https://github.com/BankNatchapol/DQI-Circuit/tree/main).\n",
    "Considering the resources given by their research and the simplicity of the code we will not go into large detail on what happens here. If anything remains unclear, do not hesitate to reach out to us! (Or the original authors)\n",
    "What this code does in essence is to calculate the necessary operations to bring the classical input matrix to [reduced row echelon form (rref)](https://en.wikipedia.org/wiki/Row_echelon_form). These may be a series of row swaps or row additions. A series of quantum operations is then returned, where the swaps are replaced by [swap()](../../reference/Primitives/generated/qrisp.swap.rst) gates and the additions by [cx()](../../reference/Primitives/generated/qrisp.cx.rst) gates, applied to the column which augments the matrix, i.e. the syndrome register ``qv_syndrome``, as shown in the next step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587c6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_jordan_operations_general(matrix):\n",
    "\n",
    "    m = len(matrix)\n",
    "    num_cols = len(matrix[0])\n",
    "    n = num_cols - 1  # last column is RHS\n",
    "    # work on a copy\n",
    "    mat = [row.copy() for row in matrix]\n",
    "    operations = []\n",
    "    pivot_row = 0\n",
    "    pivot_col = 0\n",
    "    # perform Gauss-Jordan procedure\n",
    "    while pivot_row < m and pivot_col < n:\n",
    "        # find pivot in this column at or below pivot_row\n",
    "        pivot_idx = None\n",
    "        for r in range(pivot_row, m):\n",
    "            if mat[r][pivot_col] == 1:\n",
    "                pivot_idx = r\n",
    "                break\n",
    "        if pivot_idx is None:\n",
    "            pivot_col += 1\n",
    "            continue\n",
    "\n",
    "        # swap into pivot position if needeAd\n",
    "        if pivot_idx != pivot_row:\n",
    "            # append the correct operations\n",
    "            operations.append(('swap', pivot_row, pivot_idx))\n",
    "            mat[pivot_row], mat[pivot_idx] = mat[pivot_idx], mat[pivot_row]\n",
    "\n",
    "        # eliminate other rows\n",
    "        pivot_data = mat[pivot_row]\n",
    "        for r in range(m):\n",
    "            if r != pivot_row and mat[r][pivot_col] == 1:\n",
    "            # append the correct operations\n",
    "                operations.append(('xor', pivot_row, r))\n",
    "                # XOR rows from pivot_col onward\n",
    "                row_r = mat[r]\n",
    "                row_r[pivot_col:] = [a ^ b for a, b in zip(row_r[pivot_col:], pivot_data[pivot_col:])]\n",
    "\n",
    "        pivot_row += 1\n",
    "        pivot_col += 1\n",
    "\n",
    "    return operations, mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792cb8e6",
   "metadata": {},
   "source": [
    "The following ``syndrome_decoding`` function is then the application of the gates extracted in the previous step, applied to the correct qubits from the syndrome register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87221f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qrisp import cx, swap\n",
    "def syndrome_decoding(matrix, qv_syndrome):\n",
    "\n",
    "    if isinstance(matrix, np.ndarray):\n",
    "        mat_list = matrix.tolist()\n",
    "    # extract the gates resulting from the Gauss-Jordan elimination \n",
    "    ops, mat = gauss_jordan_operations_general(mat_list)\n",
    "    num_qubits = len(mat_list)\n",
    "\n",
    "    # apply the gates on the syndrome register\n",
    "    for op_type, src, tgt in ops:\n",
    "        if op_type == \"swap\":\n",
    "            swap(qv_syndrome[src][0], qv_syndrome[tgt][0])\n",
    "        elif op_type == \"xor\":\n",
    "            cx(qv_syndrome[src][0], qv_syndrome[tgt][0])\n",
    "    \n",
    "    return mat , qv_syndrome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02690d11",
   "metadata": {},
   "source": [
    "**Attention!** This decoding procedure may result in erroneous decodings. We only want to consider the states, where the decoding was succesful. Since for a correctly decoded syndrome the error register will be in the all $\\ket{0}$-state this is easily achieved by post-selecting our final results on the measurement of the error register being n $0$s. This can also be seen when we check our final results later on.\n",
    "The only remaining step is to apply a Hadamard transform, after which the procedure is complete.\n",
    "We can now use these building blocks to solve an actual optimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5bca0",
   "metadata": {},
   "source": [
    "## DQI example for max-XORSAT\n",
    "\n",
    "The following section illustrates the internal workings of the [DQI()](../../reference/Algorithms/DQI.rst) function. The subroutines shown below are encapsuled in this function and will be exectuded upon calling it.\n",
    "\n",
    "As a final example, let us revisit the entire workflow and apply it to solve a max-Cut optimization problem. We start by defining the problem matrix $B$ and the solution constraints $\\textbf{v}$, which consists entirely of ones, since any solution is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([\n",
    "    [0, 1, 1, 1, 1, 0],\n",
    "    [1, 0, 0, 0, 1, 1],\n",
    "    [1, 0, 0, 1, 0, 0],\n",
    "    [1, 0, 1, 0, 1, 1],\n",
    "    [1, 1, 0, 1, 0, 1],\n",
    "    [0, 1, 0, 1, 1, 0]\n",
    "])\n",
    "\n",
    "v = np.array(\n",
    "    [1, 1, 1, 1, 1, 1],\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5013c6",
   "metadata": {},
   "source": [
    "\n",
    "This will result in the following graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.from_numpy_array(B)\n",
    "nx.draw(G, with_labels=True)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a257be",
   "metadata": {},
   "source": [
    "Let us go through the routine.\n",
    "We start by defining our two [QuantumArrays](../../reference/Core/QuantumArray.rst) ``qa_error`` and ``qa_syndrome``, representing the error and syndrome register respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e539720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qrisp import QuantumFloat, QuantumArray\n",
    "m = B.shape[0]\n",
    "q_type = QuantumFloat(1, 0)\n",
    "qa_error = QuantumArray(qtype= q_type , shape=(m,))\n",
    "\n",
    "# create syndrome quantumArray\n",
    "qa_syndrome = QuantumArray(qtype= q_type , shape=(m,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ec43a3",
   "metadata": {},
   "source": [
    "Next, we prepare the correctly weighted Dicke state.\n",
    "The function ``get_optimal_w`` is used to compute the weight coefficients, and ``uae_encoding`` distributes them across the error register ``qa_error``. A final call to the ``dicke_state`` preparation routine then produces the desired superposition state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941c1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l can be chosen to be equal to m, or as rank(B) as an optimized version (or even more optimized)\n",
    "# --> it defines the uae_eigenvector consideration and size qv_inner\n",
    "# default arguments for MAX-XOR-SAT\n",
    "p=2  \n",
    "r=1\n",
    "l=2\n",
    "princ_eigenvec = get_optimal_w(m,l,p,r)\n",
    "\n",
    "# UAE encoding encoding\n",
    "uae_encoding(qa_error, m, princ_eigenvec)\n",
    "\n",
    "\n",
    "from qrisp.alg_primitives.dicke_state_prep import dicke_state\n",
    "dicke_state(qa_error[::-1], len(qa_error)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57731e2b",
   "metadata": {},
   "source": [
    "We continue with the problem specific encodings, namely the specific phase encoding and constraint encoding, via the respective ``specific_phase_encoding`` and ``constraint_encoding`` functions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phase encoding\n",
    "specific_phase_encoding(qa_error, v)\n",
    "\n",
    "# constraint encoding\n",
    "qa_error, qa_syndrome = constraint_encoding(qa_error, qa_syndrome, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c19929d",
   "metadata": {},
   "source": [
    "We have now reached the core of the algorithm — the decoding step.\n",
    "As explained earlier, we apply the classical Gauss–Jordan elimination procedure ``syndrome_decoding`` and extract the corresponding quantum gates to be applied to the syndrome register ``qa_syndrome``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e051256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "syndrome_decoding(B.T, qa_syndrome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb5cc9e",
   "metadata": {},
   "source": [
    "We then further encode these actions on the error register ``qa_error``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a36e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(m):\n",
    "    cx(qa_syndrome[i], qa_error[i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb12a6c",
   "metadata": {},
   "source": [
    "And we invert the ``syndrome_decoding`` step for proper uncomputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qrisp import invert\n",
    "with invert():\n",
    "    syndrome_decoding(B.T, qa_syndrome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3aff96",
   "metadata": {},
   "source": [
    "The last step is then the aforementioned Hadamard-transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499d1ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qrisp import h\n",
    "h(qa_syndrome)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfe8c34",
   "metadata": {},
   "source": [
    "And finally, we measure and post-select on the correctly uncomputed error register, i.e. the ones where the ``qa_error`` is in all $\\ket{0}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qrisp import multi_measurement\n",
    "\n",
    "# get all correct solutions\n",
    "res_dict = multi_measurement([qa_error,qa_syndrome])\n",
    "\n",
    "corr_sols_dqi = {}\n",
    "max_val = max(res_dict.values())\n",
    "for key,val in res_dict.items():\n",
    "    cor_val = True\n",
    "    for i in range(len(key[0])):\n",
    "        if key[0][i]!= 0:\n",
    "            cor_val = False\n",
    "            break\n",
    "    if cor_val:\n",
    "        #print(key, val)  \n",
    "        corr_sols_dqi.setdefault(''.join(map(str, key[1])),val)\n",
    "\n",
    "print(corr_sols_dqi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dae504",
   "metadata": {},
   "source": [
    "Et voilá! We have executed all steps to find an optimal solution to the maxCut problem via the DQI algorithm! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a36b8bf",
   "metadata": {},
   "source": [
    "## Checking the results\n",
    "\n",
    "Let us now examine the results.\n",
    "We aim to compare them with a brute-force solution. The following can also be found in [Patamawisut's github repository](https://github.com/BankNatchapol/DQI-Circuit/blob/main/src/dqi/utils/solver.py>), where he provides a similar plot for his solution. For our purpose we need quite a few adjustements, so the full function is provided at the end of this tutorial as supplementary material. It is lengthy, but dont fret, you can use it out of the box! \n",
    "\n",
    "What we can see here is a comparison between the likelyhood of a result appearing as a result of our DQI algorithm, plotted against to objective value of a solutions aquired via brute force.\n",
    "The left $x$-axis, corresponding to the blue curve, represents the objective value of each bitstring, whereas the right $x$-axis describes the measurement probabilities for each bitstring in our final post-selected state. Those are plotted as red bars. On the $y$-axis we have every possible 6-digit bitstring.\n",
    "Remarkably, all high objective value results appear with the highest likelyhood among our post-selected states!\n",
    "\n",
    "<img src=\"../../_static/dqi_result_plot.png\" class=\"align-center\" width=\"1600\" alt=\"DQI results v. brute force\" />\n",
    "\n",
    "Congratulations, you have implemented the full version of the DQI algorithm and are now able to tackle optimization problems all on your own and can investigate the results with adequate vizualisation! Check out the next section for suggestions on where to go from here.\n",
    "\n",
    "\n",
    "## Further reading\n",
    "\n",
    "\n",
    "The interested reader has many avenues to explore, starting with other use cases from the [DQI paper](https://arxiv.org/abs/2408.08292), namely general LINSAT and OPI. These have not yet been implemented in Qrisp — if you are interested in contributing or need guidance, feel free to reach out!\n",
    "Another promising avenue is the belief propagation approach to syndrome decoding, which, according to the original work, appears to offer the best potential for achieving true quantum advantage with the DQI algorithm.\n",
    "Should you be interested in resource analysis, we again refer to [Patamawisut's paper](https://arxiv.org/abs/2504.18334), where he gives a detailed description on all aspects of the algorithm.\n",
    "\n",
    "You have reached the end of the tutorial, we hope you had alot of fun! If you would like to explore Qrisp more, go have a look at our other tutorials! \n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "[1] [Natchapol Patamawisut et al., *Quantum Circuit Design for Decoded Quantum Interferometry*, 2025, arXiv: 2504.18334](https://arxiv.org/abs/2504.18334)\n",
    "\n",
    "\n",
    "## Supplementary material\n",
    "\n",
    "\n",
    "**Note**: The functions found below are an adjusted versions from the ones found in [N. Patamawisut's github repo](https://github.com/BankNatchapol/DQI-Circuit/tree/main), \n",
    "They include the function used to create the combined histogram and spline plot shown in Figure 2.\n",
    "\n",
    "To use this function, evaluate your DQI instance to obtain the final state, then post-select on the $\\ket{0}$ state in the ``qa_error`` register. Additional supplementary functions are provided below, including the brute-force solver used for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a4c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import product\n",
    "from typing import Callable, List, Tuple, Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def _enumerate_solutions(num_vars: int,score_fn: Callable[[Tuple[int, ...]], int]):\n",
    "\n",
    "    results = []\n",
    "    for bits in product([0,1], repeat=num_vars):\n",
    "        results.append((bits, score_fn(bits)))\n",
    "    # sort so best scores come first\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "\n",
    "def max_xorsat_all_solutions(G: nx.Graph) -> Tuple[List[Dict[int,int]], int]:\n",
    "\n",
    "    def score(bits: Tuple[int,...]) -> int:\n",
    "        return sum((bits[i] ^ bits[j]) == 1 for i, j in G.edges())\n",
    "\n",
    "    raw = _enumerate_solutions(G.number_of_nodes(), score)\n",
    "    best_score = raw[0][1]\n",
    "    # collect all assignments tying that best_score\n",
    "    best = [bits for bits, s in raw if s == best_score]\n",
    "    return ([{i: bits[i] for i in range(len(bits))} for bits in best], best_score)\n",
    "\n",
    "\n",
    "def brute_force_max(B: np.ndarray, v: np.ndarray) -> List[Tuple[str,int]]:\n",
    "\n",
    "    m, n = B.shape\n",
    "\n",
    "    def score(bits: Tuple[int,...]) -> int:\n",
    "        x = np.array(bits, dtype=int)\n",
    "        return int(np.sum((-1)**(B.dot(x)+v)))\n",
    "\n",
    "    raw = _enumerate_solutions(n, score)\n",
    "    # return sorted ascending by bitstring integer (you can re-sort here if you like)\n",
    "    # or leave descending by score—choose whichever API you prefer\n",
    "    return [(\"\".join(map(str,bits)), sc) for bits, sc in raw]\n",
    "\n",
    "\n",
    "brute_force_results = brute_force_max(B, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91a1ae9",
   "metadata": {},
   "source": [
    "And below you can find the function to create the plot spline/histogram plot for the result comparison!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef0ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "def plot_results_union_matplotlib(\n",
    "    brute_force_results: List[Tuple[str, int]],\n",
    "    dqi_results: Dict[str, int],\n",
    "    plot_name: str = \"Comparison of DQI and True Objective Values\",\n",
    "    \n",
    "    spline_smoothing: float = 1.0,\n",
    "    left_axis_margin: float = 0.2,  # fraction of max to leave above the curve\n",
    "    x_label_rotation: float = 60 \n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Dual-axis Matplotlib chart: brute-force objective vs. DQI probability.\n",
    "    Secondary axis centered on 0 to align with primary axis.\n",
    "    Primary axis has a tighter cutoff near the max value.\n",
    "    \"\"\"\n",
    "    if not brute_force_results:\n",
    "        raise ValueError(\"brute_force_results must be non-empty\")\n",
    "\n",
    "    # determine full bit-length from brute-force labels\n",
    "    full_len = len(brute_force_results[0][0])\n",
    "\n",
    "    # normalize DQI keys\n",
    "    norm_dqi: Dict[str, int] = {}\n",
    "    for key, count in dqi_results.items():\n",
    "        parts = key.split()\n",
    "        if len(parts) == 2:\n",
    "            prefix, suffix = parts\n",
    "        else:\n",
    "            prefix, suffix = \"\", parts[0]\n",
    "        bits = suffix\n",
    "        if len(bits) < full_len:\n",
    "            bits = \"0\" * (full_len - len(bits)) + bits\n",
    "        full_bits = (prefix + \" \" + bits) if prefix else bits\n",
    "        norm_dqi[full_bits] = norm_dqi.get(full_bits, 0) + count\n",
    "    \n",
    "    prefix = \"\"\n",
    "    if dqi_results:\n",
    "        key_split = list(dqi_results.keys())[0].split(\" \")\n",
    "        if len(key_split) == 2:\n",
    "            prefix = \"0\"*len(key_split[0]) \n",
    "    bf_dict = {f\"{prefix} {label}\".strip(): val for label, val in brute_force_results}\n",
    "    for bits in norm_dqi:\n",
    "        if bits not in bf_dict:\n",
    "            bf_dict[bits] = 0\n",
    "\n",
    "    # union of all labels\n",
    "    all_keys = set(bf_dict) | set(norm_dqi)\n",
    "    sorted_keys = sorted(all_keys, key=lambda k: int(k.replace(\" \", \"\"), 2))\n",
    "\n",
    "    # prepare series\n",
    "    bf_values  = [bf_dict.get(k, 0) for k in sorted_keys]\n",
    "    ext_counts = [norm_dqi.get(k, 0) for k in sorted_keys]\n",
    "    total_ext  = sum(ext_counts)\n",
    "    ext_probs  = [(c / total_ext) if total_ext else 0 for c in ext_counts]\n",
    "\n",
    "    x = np.arange(len(sorted_keys))\n",
    "\n",
    "    # start plot\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "    # spline smoothing for bf_values if more than 3 points\n",
    "    if len(x) > 3:\n",
    "        spline = UnivariateSpline(x, bf_values, s=spline_smoothing*len(x))\n",
    "        x_smooth = np.linspace(x.min(), x.max(), 10000)\n",
    "        bf_smooth = spline(x_smooth)\n",
    "        \n",
    "        # clip spline to original min/max\n",
    "        bf_smooth = np.clip(bf_smooth, min(bf_values), max(bf_values))\n",
    "        \n",
    "        ax1.plot(x_smooth, bf_smooth, color=\"blue\", label=\"Objective Value\")\n",
    "    else:\n",
    "        ax1.plot(x, bf_values, color=\"blue\", label=\"Objective Value\")\n",
    "\n",
    "    # set tighter y-axis using clipped spline\n",
    "    ax1.set_ylim(min(bf_values) - 0.05*abs(min(bf_values)),\n",
    "                max(bf_smooth) + left_axis_margin*max(bf_values))\n",
    "\n",
    "    ax1.fill_between(x_smooth, bf_smooth, color=\"blue\", alpha=0.2)\n",
    "    ax1.set_ylabel(\"Objective Value\", color=\"blue\")\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "\n",
    "    # tighter y-axis range for left axis\n",
    "    bf_max = max(bf_values) if bf_values else 1\n",
    "    bf_min = min(bf_values) if bf_values else 0\n",
    "    ax1.set_ylim(-(bf_max + bf_max*left_axis_margin), bf_max + bf_max*left_axis_margin)\n",
    "\n",
    "    # secondary axis for DQI probabilities\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # make secondary y-axis symmetric around 0\n",
    "    dqi_max = max(ext_probs) if ext_probs else 0.1\n",
    "    #ax2.set_ylim(-dqi_max- dqi_max*0.2, dqi_max+ dqi_max*0.2)\n",
    "    ax2.set_ylim(-dqi_max - dqi_max*0.2 , dqi_max+ dqi_max*0.2)\n",
    "    # plot bars centered on 0\n",
    "    ax2.bar(x, ext_probs, alpha=0.6, color=\"red\", label=\"DQI (Probability)\", bottom=0)\n",
    "\n",
    "    ax2.set_ylabel(\"Probability (DQI)\", color=\"red\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(sorted_keys, rotation=x_label_rotation, ha=\"right\")\n",
    "    ax1.set_title(plot_name)\n",
    "\n",
    "    # combine legends\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    bars, blabels = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines + bars, labels + blabels, loc=\"upper center\", ncol=2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60611b5",
   "metadata": {},
   "source": [
    "And the appropriate function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbad78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_union_matplotlib(\n",
    "    brute_force_results,\n",
    "    corr_sols_dqi,\n",
    "    plot_name=\"Comparison of DQI Results with True Objective Values (Post-selected on |0⟩)\",\n",
    "    spline_smoothing=1.3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".docvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
